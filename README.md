<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type">




</head><body class="c26"><div><p class="c5 c15"><span class="c24 c25"></span></p></div><p class="c5 c15"><span class="c10"></span></p><p class="c5 c15"><span class="c10"></span></p><p class="c5 c15"><span class="c10"></span></p><p class="c5 c29"><span class="c10">&nbsp;</span></p><p class="c5 c29 c15"><span class="c10"></span></p><p class="c5 c18"><span class="c16">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; PROJECT REPORT</span></p><p class="c5 c18 c15 c27"><span class="c16"></span></p><p class="c5 c18 c15 c27"><span class="c16"></span></p><p class="c5 c14"><span class="c32">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c9">Dt.20-11-2016</span></p><p class="c5 c18 c28"><span class="c30">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;</span><span class="c17">CS 663</span><span class="c9">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c5 c28"><span class="c9">&nbsp; &nbsp;</span></p><p class="c5 c28 c15"><span class="c9"></span></p><p class="c5 c15"><span class="c9"></span></p><p class="c21"><span class="c9">Detection of faces by detecting regions of skin from color images</span></p><p class="c21"><span class="c9">(Implemented in C++ - opencv2)</span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c15"><span class="c9"></span></p><p class="c5 c6"><span class="c9"></span></p><p class="c5 c20"><span class="c9">SURYA TEJ - 140050055</span></p><p class="c5 c20"><span class="c9">SRINIVAS NAIK BHUKYA - 140050064</span></p><p class="c5 c20"><span class="c9">CHAITANYA RAJESH BANALA - 140050073</span></p><p class="c5"><span class="c1">Problem Statement :</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c0">Detection of faces by detecting regions of skin from color images.We extended this to also use </span></p><p class="c5"><span class="c0">(i) webcam for live face detection </span></p><p class="c5"><span class="c0">(ii) any video properly formatted</span></p><p class="c5"><span class="c0">(iii) a color image</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c0">Usage is mentioned in README.</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c17">Motivation :</span></p><p class="c5"><span class="c0">Detection of the human face is very useful in automatic face recognition, video surveillance, human-computer communication and large-scale face image retrieval systems. The first and foremost important step in any of these systems is the accurate detection of the presence and the position of the human faces in an image or video.</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c17">Overview:</span></p><ul class="c13 lst-kix_pkq6t7c2w9j-0 start"><li class="c2"><span class="c0">The algorithm uses a combination of RGB-HS-CbCr color spaces for the detection of &nbsp;human faces. Skin regions are extracted using a set of bounding rules based on the skin color distribution obtained from a training set.</span></li><li class="c2"><span class="c0">The model we have used utilizes the additional hue and chrominance information of the image on top of standard RGB properties to properly differentiate between skin pixels and non-skin pixels.</span></li><li class="c2"><span class="c0">Two region properties Face Detection phase &ndash; box ratio and eccentricity were used to classify the shape of each skin region after getting skin detected part of the image to report if it is face region or not. </span></li><li class="c2"><span class="c0">This project is done in C++ using opencv libraries.We did not use any direct existing libraries for face detection.</span></li></ul><p class="c5 c15"><span class="c1"></span></p><p class="c5"><span class="c1">Procedure:</span></p><p class="c5"><span class="c0">The procedure involves two main steps :</span></p><p class="c5"><span class="c0">(i) Skin Detection</span></p><p class="c5"><span class="c0">(ii) Face Detection using the skin detected intermediate result obtained from step (i)</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c0">The procedure is explained using a sample image and applying operations on it.The basic algorithm we used is same as the one explained in research paper (mentioned in references section).But In the report we tried to explain the algo using the code we have written.</span></p><p class="c5"><span class="c0">Let us take a sample image </span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 413.50px; height: 251.00px;"><img alt="Original Image_screenshot_19.11.2016.png" src="images/image7.png" style="width: 413.50px; height: 251.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c23">Skin Detection</span><span class="c9">&nbsp;:</span></p><ul class="c13 lst-kix_jkgjlj1ttztq-0 start"><li class="c2"><span class="c0">The given image is in RGB color space, first step is to get two more color spaces YCrCb and HSV of the image. We use these color-spaces to get the intensities of pixels in all the color spaces and mark the pixels as skin pixel using those values.</span></li></ul><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We do this by using the functions :</span></p><p class="c5 c14"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cvtColor(input,ycrcbimg,cv::COLOR_BGR2YCrCb)</span></p><p class="c5 c14"><span class="c0">&nbsp; &nbsp; `&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cvtColor(input,hsvimg,CV_BGR2HSV)</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 304.02px; height: 171.50px;"><img alt="YCrCb Color Space_screenshot_19.11.2016.png" src="images/image5.png" style="width: 304.02px; height: 171.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 309.50px; height: 174.15px;"><img alt="HSV Color Space_screenshot_19.11.2016.png" src="images/image1.png" style="width: 309.50px; height: 174.15px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c11"><span class="c3">YCrCb color space&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;HSV color space</span></p><p class="c5 c18 c15"><span class="c0"></span></p><ul class="c13 lst-kix_jkgjlj1ttztq-0"><li class="c2"><span class="c0">Now filter out the skin pixels using the values of RGB , YCrCb , HSV using the max and min boundary values for each of intensity values.These values were found using the training dataset which gave good results.</span></li></ul><p class="c5"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c3">For e.g.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="c0">(R&gt;220) &amp;&amp; (G&gt;210) &amp;&amp; (B&gt;170) &amp;&amp; (abs(R-G)&lt;=15) &amp;&amp; (R&gt;B) &amp;&amp; (G&gt;B)</span></p><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;and </span></p><p class="c5"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(CR&gt;=133) &amp;&amp; (CR&lt;=173</span><span class="c3 c24">) etc. </span></p><p class="c5 c18"><span class="c3">which are mentioned in the research paper referenced in the References section of the report.</span><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><ul class="c13 lst-kix_jkgjlj1ttztq-0"><li class="c2"><span class="c0">After applying all the filters using combination of &nbsp;colorspaces we get the following binary skin image.</span></li></ul><p class="c5"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 491.50px; height: 232.00px;"><img alt="Skin Image_screenshot_19.11.2016.png" src="images/image4.png" style="width: 491.50px; height: 232.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Skin detected image of given image</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c12">Face Detection :</span></p><ul class="c13 lst-kix_qi7ba6q61o77-0 start"><li class="c2"><span class="c4">First step is to fill all the holes in a connected set of pixels which we call connected components.This is done using </span><span class="c7">imfill</span><span class="c0">&nbsp;function written in the code.After filling the holes we get the following image.</span></li></ul><p class="c5"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 567.50px; height: 262.00px;"><img alt="afterfillingholes_screenshot_19.11.2016.png" src="images/image3.png" style="width: 567.50px; height: 262.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Image after filling holes</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5 c18"><span class="c0">Notice that all the holes in faces (eg. eyes ) are now filled and the image is &nbsp; </span></p><p class="c5 c18"><span class="c0">divided into separate components.</span></p><p class="c5 c15"><span class="c0"></span></p><ul class="c13 lst-kix_qi7ba6q61o77-0"><li class="c2"><span class="c4">Next step of the Face Detection is to divide the above obtained image into separate connected components in the function &ldquo;</span><span class="c7">getconnectedcomponents</span><span class="c4">&rdquo; which primarily calls &ldquo;</span><span class="c7">findconnectedblobs</span><span class="c0">&rdquo; that separates each connected components and stores them into the &ldquo;blobs&rdquo; vector which has the list of all connected pixels as a vector.Each blob is then randomly colored to show that they have been indeed separated into separate connected components.</span></li></ul><p class="c5"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 564.00px; height: 311.50px;"><img alt="connected components_screenshot_19.11.2016.png" src="images/image8.png" style="width: 564.00px; height: 311.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Each connected component colored randomly</span></p><ul class="c13 lst-kix_qi7ba6q61o77-0"><li class="c2"><span class="c4">Now iterate through every connected component to detect faces.We use box ratio and eccentricity to filter out faces which are stored in </span><span class="c7">faceblobs</span><span class="c4">&nbsp;in the function </span><span class="c7">getface. </span><span class="c0">Ratio and eccentricity (mentioned in the research paper)are calculated by first creating a bounding box to every component and finding values xmin,xmax,ymin,ymax(Full logic is in the function &ldquo;getallfaces&rdquo; ).We then use the values to filter out blobs which might be faces : </span></li></ul><p class="c5 c15"><span class="c0"></span></p><p class="c5 c18"><span class="c0">blobs[i].size() &gt; 1500 &amp;&amp; ratio &gt;=0.4 &nbsp;&amp;&amp; ratio &lt;= 1.8 &amp;&amp; ecc &gt;= 0.25 &amp;&amp; ecc&lt;=0.97</span></p><p class="c5 c18 c15"><span class="c0"></span></p><ul class="c13 lst-kix_qi7ba6q61o77-0"><li class="c2"><span class="c0">After obtaining the &ldquo;faceblobs&rdquo; we now draw a rectangle in the function drawrectangle which takes in original image and faceblobs and draws rectangle over every faceblob with red.</span></li></ul><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Mat drawrectangle(Mat img,vector&lt;vector&lt;Point2i&gt; &gt;faceblobs)</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5 c14"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; output.at&lt;cv::Vec3b&gt;(y,x)[0] = 0;</span></p><p class="c5 c14"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output.at&lt;cv::Vec3b&gt;(y,x)[1] = 0;</span></p><p class="c5 c14"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; output.at&lt;cv::Vec3b&gt;(y,x)[2] = 255;</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c0">Final image with detected faces :</span></p><p class="c5"><span class="c4">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 352.00px;"><img alt="Face detected_screenshot_19.11.2016.png" src="images/image6.png" style="width: 624.00px; height: 352.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c1">Experimental Results:</span></p><p class="c5"><span class="c0">The model was evaluated on test data set of 20 images and 2 videos, the images and videos were randomly selected from the Internet, each comprising of some near-frontal faces. The test images and videos consists of various illuminations and poses.</span></p><p class="c5 c15"><span class="c12"></span></p><p class="c5"><span class="c12">Metrics calculated for each image:</span></p><p class="c5 c15"><span class="c12"></span></p><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp;no. of false detections</span></p><ul class="c13 lst-kix_k1gltjf5l1wi-0 start"><li class="c2"><span class="c0">False Detection Count(FDC) = &nbsp; &nbsp; --------------------------------------- &nbsp; &nbsp;&times; 100%</span></li></ul><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; total number of detections</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;no. of correctly detected faces</span></p><ul class="c13 lst-kix_k1gltjf5l1wi-0"><li class="c2"><span class="c0">Detection Success Count (DSC) = &nbsp;------------------------------------------- &nbsp; &nbsp;&times; 100%</span></li></ul><p class="c5"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;total number of faces</span></p><p class="c5"><span class="c3 c24">*(where the number of correctly detected faces is equivalent to the number of faces minus the number of false dismissals)</span></p><p class="c5 c15"><span class="c3 c24"></span></p><p class="c5"><span class="c0">We seek to have results with high DSC and low FDC values to judge performance of the model used.</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c12">Results for Training Images:</span></p><p class="c5 c15"><span class="c12"></span></p><p class="c5"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 568.00px; height: 560.00px;"><img alt="test.png" src="images/image2.png" style="width: 568.00px; height: 560.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c4">All the images and videos used for testing are included in the submission folder.</span></p><p class="c5 c15"><span class="c1"></span></p><p class="c5"><span class="c1">Observations:</span></p><ul class="c13 lst-kix_ord33ngtds74-0 start"><li class="c2"><span class="c0">Experimental results tells us that the model achieves good detection success rates for near-frontal faces of varying orientations, skin color and background.</span></li><li class="c2"><span class="c0">In skin detection phase, We first tried to implement detection based on only two color spaces like RGB and HSV or RGB and YCbCr space values but the use of all 3 color spaces showed very good face detection accuracy.</span></li><li class="c2"><span class="c0">Images with smaller faces and very low quality illuminations are not detected properly.</span></li></ul><p class="c5 c15"><span class="c1"></span></p><p class="c5"><span class="c1">Summary and Challenges Faced:</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c0">The main challenges encountered in face detection is to cope with a wide variety of variations in the human face such as posture and scale, face orientation, facial expression, ethnicity and skin color. External factors such as occlusion, complex backgrounds inconsistent illumination conditions and quality of the image may also contribute significantly to the overall problem.</span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c0">The resulting segmented skin color regions have three common issues:</span></p><p class="c5"><span class="c0">a) Regions are fragmented and often contain holes and gaps.</span></p><p class="c5"><span class="c0">b) Occluded faces or multiple faces of close proximity may result in erroneous labeling.</span></p><p class="c5"><span class="c0">c) Extracted skin color regions may not necessarily be face regions. There are possibilities that certain skin regions may belong to exposed limbs (arms and legs) and also foreground and background objects that have a high degree of similarity to skin color. </span></p><p class="c5 c15"><span class="c0"></span></p><p class="c5"><span class="c24 c31">Contribution:</span></p><p class="c5"><span class="c12">140050064: </span></p><p class="c5"><span class="c0">Code upto skin detection phase.</span></p><p class="c5"><span class="c4">Testing and report.</span></p><p class="c5"><span class="c12">140050073:</span></p><p class="c5"><span class="c0">Code for dividing the image into connected components, labelling them and facedetection,.</span></p><p class="c5"><span class="c4">Testing and report.</span></p><p class="c5"><span class="c12">140050055:</span></p><p class="c5"><span class="c0">Code for dividing the image into connected components, facedetection.</span></p><p class="c5"><span class="c0">Testing and report.</span></p><p class="c5"><span class="c12">References:</span></p><ol class="c13 lst-kix_d7d0lntslmlf-0 start" start="1"><li class="c2"><span class="c19"><a class="c8" href="https://www.google.com/url?q=https://www.cs.rutgers.edu/~elgammal/pub/skin.pdf&amp;sa=D&amp;ust=1570108995230000">Skin Detection</a></span><span class="c4">(https://www.cs.rutgers.edu/~elgammal/pub/skin.pdf)</span><span class="c0">&nbsp;- a Short Tutorial-Ahmed Elgammal, Crystal Muang and Dunxu Hu Department of Computer Science, Rutgers University, Piscataway, NJ, 08902, USA</span></li><li class="c2"><span class="c19"><a class="c8" href="https://www.google.com/url?q=http://www.softcomputing.net/wict11_4.pdf&amp;sa=D&amp;ust=1570108995230000">Face Detection Using Skin Tone Segmentation</a></span><span class="c4">(http://www.softcomputing.net/wict11_4.pdf)</span><span class="c0">-Sayantan Thakur , Sayantanu Paul , Ankur Mondal</span></li><li class="c2"><span class="c19"><a class="c8" href="https://www.google.com/url?q=http://docs.opencv.org/2.4.0/&amp;sa=D&amp;ust=1570108995230000">Documentation of opencv2</a></span><span class="c0">(http://docs.opencv.org/2.4.0/)</span></li></ol></body></html>
